<application>
  <component name="AppStorage">
    <option name="newTranslationDialogHeight" value="793" />
    <option name="newTranslationDialogWidth" value="992" />
    <option name="newTranslationDialogX" value="691" />
    <option name="newTranslationDialogY" value="156" />
    <histories>
      <item value="Intentionally ignore. Prefer previous error." />
      <item value="interceptor Chain" />
      <item value="plugin All" />
      <item value="Reuse Executor" />
      <item value="Batch Executor" />
      <item value="Reuse" />
      <item value="executor" />
      <item value="Executor" />
      <item value="Configurable Property Accessor" />
      <item value="Accessor" />
      <item value="actual" />
      <item value="Eagerly cache singletons to be able to resolve circular references even when triggered by lifecycle interfaces like BeanFactoryAware." />
      <item value="Eagerly cache singletons to be able to resolve circular references" />
      <item value="Allow post-processors to modify the merged bean definition." />
      <item value="Instantiate the bean." />
      <item value="BeanPostProcessor before instantiation of bean failed" />
      <item value="Give BeanPostProcessors a chance to return a proxy instead of the target bean instance." />
      <item value="Validation of method overrides failed" />
      <item value="Prepare method overrides" />
      <item value="Make sure bean class is actually resolved at this point, and clone the bean definition in case of a dynamically resolved Class which cannot be stored in the shared merged bean definition." />
      <item value="Use prototype bean definition, to avoid registering bean as dependent bean." />
      <item value="release" />
      <item value="This node has already set status asking a release to signal it, so it can safely park." />
      <item value="Proceed in 3 steps: 1. If fewer than corePoolSize threads are running, try to start a new thread with the given command as its first task. The call to addWorker atomically checks runState and workerCount, and so prevents false alarms that would add threads when it shouldn't, by returning false. 2. If a task can be successfully queued, then we still need to double-check whether we should have added a thread (because existing ones died since last checking) or that the pool shut down since entry into this method. So we recheck state and if necessary roll back the enqueuing if stopped, or start a new thread if there are none. 3. If we cannot queue task, then we try to add a new thread. If it fails, we know we are shut down or saturated and so reject the task." />
      <item value="NORM PRIORITY" />
      <item value="setup to use Unsafe.compareAndSwapInt for updates" />
      <item value="Returns a default thread factory used to create new threads. This factory creates all new threads used by an Executor in the same {@link ThreadGroup}. If there is a {@link java.lang.SecurityManager}, it uses the group of {@link SystemgetSecurityManager}, else the group of the thread invoking this {@code defaultThreadFactory} method. Each new thread is created as a non-daemon thread with priority set to the smaller of {@code Thread.NORM_PRIORITY} and the maximum priority permitted in the thread group. New threads have names accessible via {@link ThreadgetName} of &lt;em&gt;pool-N-thread-M&lt;em&gt;, where &lt;em&gt;N&lt;em&gt; is the sequence number of this factory, and &lt;em&gt;M&lt;em&gt; is the sequence number of the thread created by this factory. @return a thread factory" />
      <item value="nanosecond timeout value out of range" />
      <item value="timeout value is negative" />
      <item value="priority" />
      <item value="do nothing. If start0 threw a Throwable then it will be passed up the call stack" />
      <item value="Notify the group that this thread is about to be started so that it can be added to the group's list of threads and the group's unstarted count can be decremented." />
      <item value="This method is not invoked for the main method thread or &quot;system&quot; group threads createdset up by the VM. Any new functionality added to this method in the future may have to also be added to the VM. A zero status value corresponds to state &quot;NEW&quot;." />
      <item value="preserve" />
      <item value="preserve order" />
      <item value="zero initial threshold signifies using defaults" />
      <item value="initial capacity was placed in threshold" />
      <item value="double threshold" />
      <item value="existing mapping for key" />
      <item value="-1 for 1st" />
      <item value="always check first node" />
      <item value="min treeify capacity" />
      <item value="untreeify threshold" />
      <item value="treeify threshold" />
      <item value="default initial capacity" />
      <item value="maximum capacity" />
      <item value="default load factor" />
      <item value="capacity" />
      <item value="Implementation notes. This map usually acts as a binned (bucketed) hash table, but when bins get too large, they are transformed into bins of TreeNodes, each structured similarly to those in java.util.TreeMap. Most methods try to use normal bins, but relay to TreeNode methods when applicable (simply by checking instanceof a node). Bins of TreeNodes may be traversed and used like any others, but additionally support faster lookup when overpopulated. However, since the vast majority of bins in normal use are not overpopulated, checking for existence of tree bins may be delayed in the course of table methods. Tree bins (i.e., bins whose elements are all TreeNodes) are ordered primarily by hashCode, but in the case of ties, if two elements are of the same &quot;class C implements Comparable&lt;C&gt;&quot;, type then their compareTo method is used for ordering. (We conservatively check generic types via reflection to validate this -- see method comparableClassFor). The added complexity of tree bins is worthwhile in providing worst-case O(log n) operations when keys either have distinct hashes or are orderable, Thus, performance degrades gracefully under accidental or malicious usages in which hashCode() methods return values that are poorly distributed, as well as those in which many keys share a hashCode, so long as they are also Comparable. (If neither of these apply, we may waste about a factor of two in time and space compared to taking no precautions. But the only known cases stem from poor user programming practices that are already so slow that this makes little difference.) Because TreeNodes are about twice the size of regular nodes, we use them only when bins contain enough nodes to warrant use (see TREEIFY_THRESHOLD). And when they become too small (due to removal or resizing) they are converted back to plain bins. In usages with well-distributed user hashCodes, tree bins are rarely used. Ideally, under random hashCodes, the frequency of nodes in bins follows a Poisson distribution (http:en.wikipedia.orgwikiPoisson_distribution) with a parameter of about 0.5 on average for the default resizing threshold of 0.75, although with a large variance because of resizing granularity. Ignoring variance, the expected occurrences of list size k are (exp(-0.5) pow(0.5, k) factorial(k)). The first values are: 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million The root of a tree bin is normally its first node. However, sometimes (currently only upon Iterator.remove), the root might be elsewhere, but can be recovered following parent links (method TreeNode.root()). All applicable internal methods accept a hash code as an argument (as normally supplied from a public method), allowing them to call each other without recomputing user hashCodes. Most internal methods also accept a &quot;tab&quot; argument, that is normally the current table, but may be a new or old one when resizing or converting. When bin lists are treeified, split, or untreeified, we keep them in the same relative accesstraversal order (i.e., field Node.next) to better preserve locality, and to slightly simplify handling of splits and traversals that invoke iterator.remove. When using comparators on insertion, to keep a total ordering (or as close as is required here) across rebalancings, we compare classes and identityHashCodes as tie-breakers. The use and transitions among plain vs tree modes is complicated by the existence of subclass LinkedHashMap. See below for hook methods defined to be invoked upon insertion, removal and access that allow LinkedHashMap internals to otherwise remain independent of these mechanics. (This also requires that a map instance be passed to some utility methods that may create new nodes.) The concurrent-programming-like SSA-based coding style helps avoid aliasing errors amid all of the twisty pointer operations." />
      <item value="Implementation instructions. This map normally acts as a binned (bucketed) hash table, but when the bins become too large, they are converted into bins of TreeNode s, each of which is similar to the one in java.util.TreeMap . Most methods try to use normal bins, but relay to TreeNode methods when applicable (just check the instance of the node). A TreeNode's bins can be traversed and used like any other bin, but also supports faster lookups when too populated. However, since the vast majority of normally used bins are not overfilled, checking for the existence of tree bins during the table method may be delayed. Tree bins (i.e. bins whose elements are all TreeNodes ) are mostly ordered by hashCode, but in the case of tie, if two elements belong to the same &quot;C class implements Comparable&lt;C&gt;&quot;, then their compareTo method is used for ordering. (We verify this conservatively by checking the generic type by reflection - see the method compatibleClassFor). The added complexity of the treebox is worthwhile in providing worst-case O(log n) operations when keys have different hashes or are sortable, so in the unlikely event that the hashCode() method returns a poor value or Under malicious use, performance will gracefully degrade distributed, and many keys share a hashCode, as long as they are also Comparable. (If none of these apply, we might waste about twice as much time and space as if we didn't take precautions. But the only known cases stem from poor user programming practices that are already so slow that this Hardly any difference.) Because TreeNodes are about twice the size of regular nodes, we only use them when the bin contains enough nodes to warrant usage (see TREEIFY_THRESHOLD). When they get too small (due to removal or resizing) they are converted back to normal trash. In the use of user hash codes with a good distribution, tree boxes are rarely used. Ideally, under random hashCodes, the frequencies of nodes in bins follow a Poisson distribution (http:en.wikipedia.orgwikiPoisson_distribution), with a default resizing threshold of 0.75 and an average parameter of about 0.5, although there are large differences due to resizing granularity Difference. Ignoring variance, the expected appearance for a list size k is (exp(-0.5) pow(0.5, k) factorial(k)). The first values are: 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million The root of a tree bin is normally its first node. However, sometimes (currently only on Iterator.remove ), the root may be elsewhere, but can be restored after the parent link (method TreeNode.root() ). All applicable internal methods accept a hashcode as a parameter (usually provided by public methods), allowing them to call each other without recomputing the user hashcode. Most internal methods also accept a &quot;tab&quot; parameter, which is usually the current table, but may be a new or old table when resized or converted. When the bin lists are treed, split, or not treed, we keep them in the same relative access traversal order (i.e. field Node.next) to better preserve locality, and slightly simplify calling iterator.remove The splitting and traversal processing. In order to maintain total ordering (or close as required here) between rebalances when using comparators on inserts, we compare classes and identityHashCodes as a tiebreaker. The use and conversion between normal mode and tree mode is complicated by the existence of the subclass LinkedHashMap. See below the hook methods defined to be called on insertion, deletion and access that allow LinkedHashMap internals to remain independent of these mechanisms. (This also requires passing the map instance to some utility method that might create a new node.) An SSA-based coding style like concurrent programming helps avoid aliasing errors in all the twisty pointer operations." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="62" />
        <entry key="ENGLISH" value="63" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1657603230292" />
  </component>
  <component name="Settings">
    <option name="showWordsOnStartup" value="true" />
  </component>
</application>